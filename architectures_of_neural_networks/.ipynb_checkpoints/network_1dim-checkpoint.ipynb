{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "import random\n",
    "from os import listdir\n",
    "from pandas import read_csv\n",
    "\n",
    "# loading and labeling database\n",
    "\n",
    "def load_dataset():\n",
    "    prefix = ''\n",
    "    subjects = list()\n",
    "    for folder_name in listdir('HAR_1/'):\n",
    "        directory = prefix + 'HAR_1/' + folder_name + '/'\n",
    "        for name in listdir(directory):\n",
    "            filename = directory + '/' + name\n",
    "            if not filename.endswith('.data'):\n",
    "                continue\n",
    "            df = read_csv(filename, header=None)\n",
    "            values = df.values[:, :]\n",
    "            if directory == prefix + 'HAR_1/crunches/':\n",
    "                id = 0\n",
    "            elif directory == prefix + 'HAR_1/burpees/':\n",
    "                id = 1\n",
    "            elif directory == prefix + 'HAR_1/squats/':\n",
    "                id = 2\n",
    "            elif directory == prefix + 'HAR_1/jumping_jacks/':\n",
    "                id = 3\n",
    "            elif directory == prefix + 'HAR_1/push_ups/':\n",
    "                id = 4\n",
    "            else :\n",
    "                id = 5                \n",
    "            subjects.append((values,id))\n",
    "    return subjects\n",
    "\n",
    "# creating variables\n",
    "\n",
    "subjects = load_dataset()\n",
    "randomDataset = subjects\n",
    "random.shuffle(randomDataset)  # data mixing\n",
    "training_base = []  \n",
    "training_base_0 = []\n",
    "training_base_1 = []\n",
    "test_base = []\n",
    "test_base_0 = []\n",
    "test_base_1 = []\n",
    "valid_base = []\n",
    "valid_base_0 = []\n",
    "valid_base_1 = []\n",
    "\n",
    "# establishing a database partition\n",
    "\n",
    "for x in range(len(randomDataset)):\n",
    "    if x <90:\n",
    "        test_base.append(randomDataset[x])\n",
    "    elif x >= 90 and x <180:\n",
    "        valid_base.append(randomDataset[x])    \n",
    "    else:\n",
    "        training_base.append(randomDataset[x])\n",
    "\n",
    "# splitting data and labels        \n",
    "        \n",
    "for x in test_base:\n",
    "    test_base_0.append(x[0])\n",
    "    test_base_1.append(x[1])\n",
    "\n",
    "for x in valid_base:\n",
    "    valid_base_0.append(x[0])\n",
    "    valid_base_1.append(x[1])\n",
    "        \n",
    "for x in training_base:\n",
    "    training_base_0.append(x[0])\n",
    "    training_base_1.append(x[1])\n",
    "\n",
    "# printing the number of data and labels depending on the set\n",
    "    \n",
    "print(len(test_base_0))\n",
    "print(len(test_base_1))\n",
    "\n",
    "print(len(valid_base_0))\n",
    "print(len(valid_base_1))\n",
    "\n",
    "print(len(training_base_0))\n",
    "print(len(training_base_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# converting data into tensors and giving them the appropriate number of dimensions\n",
    "\n",
    "training_np = np.asarray(training_base_0, np.float32)\n",
    "training_np_reshaped = training_np.reshape(420,1*6)\n",
    "\n",
    "test_np = np.asarray(test_base_0, np.float32)\n",
    "test_np_reshaped = test_np.reshape(90, 1*6)\n",
    "\n",
    "valid_np = np.asarray(valid_base_0, np.float32)\n",
    "valid_np_reshaped = valid_np.reshape(90, 1*6)\n",
    "\n",
    "valid_y = valid_base_1\n",
    "valid_y = to_categorical(valid_y)\n",
    "\n",
    "training_y = training_base_1\n",
    "training_y = to_categorical(training_y)\n",
    "\n",
    "\n",
    "# structure of the neural network\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(1*6,)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(6, activation='softmax'))\n",
    "\n",
    "test_y= test_base_1\n",
    "test_y= to_categorical(test_y)\n",
    "\n",
    "# compiler\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='rmsprop',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# start of the learning\n",
    "model.fit(training_np_reshaped, training_y ,epochs=30, batch_size=10, validation_data = (valid_np_reshaped, valid_y))\n",
    "\n",
    "\n",
    "# accuracy check\n",
    "test_loss, test_acc = model.evaluate(test_np_reshaped, test_y)\n",
    "\n",
    "print(test_loss, test_acc)\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# ability to view class predictions with their proper label\n",
    "\"\"\"\n",
    "predictions = model.predict(test_np_reshaped, steps = 90)\n",
    "\n",
    "for i in range(20):\n",
    "    print(predictions[i], test_y[i])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
